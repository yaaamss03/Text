{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "86755c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fc696cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The First Line:  ï»¿One morning, when Gregor Samsa woke from troubled dreams, he found\n",
      "\n",
      "The Last Line:  first to get up and stretch out her young body.\n"
     ]
    }
   ],
   "source": [
    "file = open('metamorphosis_clean.txt', 'r', encoding = 'utf8')\n",
    "lines = []\n",
    "\n",
    "for i in file:\n",
    "    lines.append(i)\n",
    "    \n",
    "print('The First Line: ', lines[0])\n",
    "print('The Last Line: ', lines[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3ff30b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One morning, when Gregor Samsa woke from troubled dreams, he found himself transformed in his bed into a horrible vermin.  He lay on his armour-like back, and if he lifted his head a little he could see his brown belly, slightly domed and divided by arches into stiff sections.  The bedding was hardly able to cover it and seemed ready to slide off any moment.'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaning the data\n",
    "data = ''\n",
    "for i in lines:\n",
    "    data = ' '.join(lines)\n",
    "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '')\n",
    "data[:360]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fb91608e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One morning  when Gregor Samsa woke from troubled dreams  he found himself transformed in his bed into a horrible vermin   He lay on his armour like back  and if he lifted his head a little he could see his brown belly  slightly domed and divided by arches into stiff sections   The bedding was hardly able to cover it and seemed ready to slide off any moment   His many legs  pitifully thin compared with the size of the rest of him  waved about helplessly as he looked    What s happened to me   he'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "new_data = data.translate(translator)\n",
    "\n",
    "new_data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3f0e3a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One morning, when Gregor Samsa woke from troubled dreams, he found himself transformed in his bed into a horrible vermin. He lay on armour-like back, and if lifted head little could see brown belly, slightly domed divided by arches stiff sections. The bedding was hardly able to cover it seemed ready slide off any moment. His many legs, pitifully thin compared with the size of rest him, waved about helplessly as looked. \"What\\'s happened me?\" thought. It wasn\\'t dream. room, proper human room altho'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = []\n",
    "\n",
    "for i in data.split():\n",
    "    if i not in z:\n",
    "        z.append(i)\n",
    "        \n",
    "data = ' '.join(z)\n",
    "data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "57a2f962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17, 53, 293, 2, 18, 729, 135, 730, 294, 8]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "\n",
    "# saving the tokenizer for predict function.\n",
    "pickle.dump(tokenizer, open('tokenizer1.pkl', 'wb'))\n",
    "\n",
    "seq_data = tokenizer.texts_to_sequences([data])[0]\n",
    "seq_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6bde83d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2617\n"
     ]
    }
   ],
   "source": [
    "voc_size = len(tokenizer.word_index) + 1\n",
    "print(voc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b6c5d83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of sequences are:  3889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 17,  53],\n",
       "       [ 53, 293],\n",
       "       [293,   2],\n",
       "       [  2,  18],\n",
       "       [ 18, 729],\n",
       "       [729, 135],\n",
       "       [135, 730],\n",
       "       [730, 294],\n",
       "       [294,   8],\n",
       "       [  8, 731]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = []\n",
    "\n",
    "for i in range(1, len(seq_data)):\n",
    "    words = seq_data[i-1:i+1]\n",
    "    seq.append(words)\n",
    "    \n",
    "print('The length of sequences are: ', len(seq))\n",
    "seq = np.array(seq)\n",
    "seq[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2f12e90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in seq:\n",
    "    X.append(i[0])\n",
    "    y.append(i[1])\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "894ec0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data is:  [ 17  53 293   2  18]\n",
      "The responses are:  [ 53 293   2  18 729]\n"
     ]
    }
   ],
   "source": [
    "print('The data is: ', X[:5])\n",
    "print('The responses are: ', y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "456ae4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(y, num_classes = voc_size)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "461c055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(voc_size, 10, input_length = 1))\n",
    "model.add(LSTM(1000, return_sequences = True))\n",
    "model.add(LSTM(1000))\n",
    "model.add(Dense(1000, activation = 'relu'))\n",
    "model.add(Dense(voc_size, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "65ce4546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 1, 10)             26170     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 1, 1000)           4044000   \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 1000)              8004000   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2617)              2619617   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,694,787\n",
      "Trainable params: 15,694,787\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "87379cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.utils.vis_utils\n",
    "from importlib import reload\n",
    "reload(keras.utils.vis_utils)\n",
    "\n",
    "\n",
    "from keras.utils.vis_utils import plot_model    \n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a9683d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow import keras\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "keras.utils.plot_model(model, to_file = 'model.png', show_layer_names = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f327ee1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2433f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"nextword1.h5\", monitor='loss', verbose=1,\n",
    "    save_best_only=True, mode='auto')\n",
    "\n",
    "reduce = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=3, min_lr=0.0001, verbose = 1)\n",
    "\n",
    "logdir='logsnextword1'\n",
    "tensorboard_Visualization = TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d44925a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f53be6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 7.8753\n",
      "Epoch 1: loss improved from inf to 7.87530, saving model to nextword1.h5\n",
      "61/61 [==============================] - 10s 66ms/step - loss: 7.8753 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 7.8621\n",
      "Epoch 2: loss improved from 7.87530 to 7.86213, saving model to nextword1.h5\n",
      "61/61 [==============================] - 4s 66ms/step - loss: 7.8621 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 7.8364\n",
      "Epoch 3: loss improved from 7.86213 to 7.83638, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 76ms/step - loss: 7.8364 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 7.6548\n",
      "Epoch 4: loss improved from 7.83638 to 7.65480, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 82ms/step - loss: 7.6548 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 7.4494\n",
      "Epoch 5: loss improved from 7.65480 to 7.44943, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 7.4494 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 7.2770\n",
      "Epoch 6: loss improved from 7.44943 to 7.27698, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 74ms/step - loss: 7.2770 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 7.1649\n",
      "Epoch 7: loss improved from 7.27698 to 7.16485, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 7.1649 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 7.0784\n",
      "Epoch 8: loss improved from 7.16485 to 7.07835, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 82ms/step - loss: 7.0784 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 7.0058\n",
      "Epoch 9: loss improved from 7.07835 to 7.00579, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 76ms/step - loss: 7.0058 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 6.9177\n",
      "Epoch 10: loss improved from 7.00579 to 6.91769, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 77ms/step - loss: 6.9177 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 6.8001\n",
      "Epoch 11: loss improved from 6.91769 to 6.80009, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 81ms/step - loss: 6.8001 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 6.6327\n",
      "Epoch 12: loss improved from 6.80009 to 6.63274, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 6.6327 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 6.4011\n",
      "Epoch 13: loss improved from 6.63274 to 6.40111, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 75ms/step - loss: 6.4011 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 6.1543\n",
      "Epoch 14: loss improved from 6.40111 to 6.15426, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 6.1543 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 5.9006\n",
      "Epoch 15: loss improved from 6.15426 to 5.90059, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 5.9006 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 5.6483\n",
      "Epoch 16: loss improved from 5.90059 to 5.64830, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 74ms/step - loss: 5.6483 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 5.3890\n",
      "Epoch 17: loss improved from 5.64830 to 5.38901, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 5.3890 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 5.1517\n",
      "Epoch 18: loss improved from 5.38901 to 5.15168, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 5.1517 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 4.8923\n",
      "Epoch 19: loss improved from 5.15168 to 4.89228, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 77ms/step - loss: 4.8923 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 4.6476\n",
      "Epoch 20: loss improved from 4.89228 to 4.64760, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 4.6476 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 4.4355\n",
      "Epoch 21: loss improved from 4.64760 to 4.43554, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 4.4355 - lr: 0.0010\n",
      "Epoch 22/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 4.2116\n",
      "Epoch 22: loss improved from 4.43554 to 4.21157, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 76ms/step - loss: 4.2116 - lr: 0.0010\n",
      "Epoch 23/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 4.0490\n",
      "Epoch 23: loss improved from 4.21157 to 4.04900, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 74ms/step - loss: 4.0490 - lr: 0.0010\n",
      "Epoch 24/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 3.8630\n",
      "Epoch 24: loss improved from 4.04900 to 3.86295, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 3.8630 - lr: 0.0010\n",
      "Epoch 25/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 3.7039\n",
      "Epoch 25: loss improved from 3.86295 to 3.70385, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 87ms/step - loss: 3.7039 - lr: 0.0010\n",
      "Epoch 26/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 3.5793\n",
      "Epoch 26: loss improved from 3.70385 to 3.57930, saving model to nextword1.h5\n",
      "61/61 [==============================] - 4s 74ms/step - loss: 3.5793 - lr: 0.0010\n",
      "Epoch 27/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 3.4486\n",
      "Epoch 27: loss improved from 3.57930 to 3.44859, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 3.4486 - lr: 0.0010\n",
      "Epoch 28/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 3.3341\n",
      "Epoch 28: loss improved from 3.44859 to 3.33411, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 82ms/step - loss: 3.3341 - lr: 0.0010\n",
      "Epoch 29/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 3.2235\n",
      "Epoch 29: loss improved from 3.33411 to 3.22347, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 77ms/step - loss: 3.2235 - lr: 0.0010\n",
      "Epoch 30/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 3.1051\n",
      "Epoch 30: loss improved from 3.22347 to 3.10511, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 77ms/step - loss: 3.1051 - lr: 0.0010\n",
      "Epoch 31/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 3.0114\n",
      "Epoch 31: loss improved from 3.10511 to 3.01136, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 81ms/step - loss: 3.0114 - lr: 0.0010\n",
      "Epoch 32/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.9288\n",
      "Epoch 32: loss improved from 3.01136 to 2.92880, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 77ms/step - loss: 2.9288 - lr: 0.0010\n",
      "Epoch 33/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.8942\n",
      "Epoch 33: loss improved from 2.92880 to 2.89419, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 74ms/step - loss: 2.8942 - lr: 0.0010\n",
      "Epoch 34/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.8064\n",
      "Epoch 34: loss improved from 2.89419 to 2.80635, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 81ms/step - loss: 2.8064 - lr: 0.0010\n",
      "Epoch 35/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.7252\n",
      "Epoch 35: loss improved from 2.80635 to 2.72522, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 81ms/step - loss: 2.7252 - lr: 0.0010\n",
      "Epoch 36/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.6589\n",
      "Epoch 36: loss improved from 2.72522 to 2.65892, saving model to nextword1.h5\n",
      "61/61 [==============================] - 4s 72ms/step - loss: 2.6589 - lr: 0.0010\n",
      "Epoch 37/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.6021\n",
      "Epoch 37: loss improved from 2.65892 to 2.60215, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 82ms/step - loss: 2.6021 - lr: 0.0010\n",
      "Epoch 38/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.5291\n",
      "Epoch 38: loss improved from 2.60215 to 2.52909, saving model to nextword1.h5\n",
      "61/61 [==============================] - 7s 123ms/step - loss: 2.5291 - lr: 0.0010\n",
      "Epoch 39/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.4663\n",
      "Epoch 39: loss improved from 2.52909 to 2.46633, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 2.4663 - lr: 0.0010\n",
      "Epoch 40/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.4234\n",
      "Epoch 40: loss improved from 2.46633 to 2.42341, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 82ms/step - loss: 2.4234 - lr: 0.0010\n",
      "Epoch 41/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.3782\n",
      "Epoch 41: loss improved from 2.42341 to 2.37822, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 75ms/step - loss: 2.3782 - lr: 0.0010\n",
      "Epoch 42/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.3415\n",
      "Epoch 42: loss improved from 2.37822 to 2.34151, saving model to nextword1.h5\n",
      "61/61 [==============================] - 4s 72ms/step - loss: 2.3415 - lr: 0.0010\n",
      "Epoch 43/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.3117\n",
      "Epoch 43: loss improved from 2.34151 to 2.31171, saving model to nextword1.h5\n",
      "61/61 [==============================] - 6s 95ms/step - loss: 2.3117 - lr: 0.0010\n",
      "Epoch 44/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.2784\n",
      "Epoch 44: loss improved from 2.31171 to 2.27838, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 77ms/step - loss: 2.2784 - lr: 0.0010\n",
      "Epoch 45/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.2555\n",
      "Epoch 45: loss improved from 2.27838 to 2.25547, saving model to nextword1.h5\n",
      "61/61 [==============================] - 4s 74ms/step - loss: 2.2555 - lr: 0.0010\n",
      "Epoch 46/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.2186\n",
      "Epoch 46: loss improved from 2.25547 to 2.21864, saving model to nextword1.h5\n",
      "61/61 [==============================] - 4s 72ms/step - loss: 2.2186 - lr: 0.0010\n",
      "Epoch 47/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.1930\n",
      "Epoch 47: loss improved from 2.21864 to 2.19297, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 77ms/step - loss: 2.1930 - lr: 0.0010\n",
      "Epoch 48/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.1053\n",
      "Epoch 48: loss improved from 2.19297 to 2.10534, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 77ms/step - loss: 2.1053 - lr: 0.0010\n",
      "Epoch 49/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.0731\n",
      "Epoch 49: loss improved from 2.10534 to 2.07306, saving model to nextword1.h5\n",
      "61/61 [==============================] - 4s 71ms/step - loss: 2.0731 - lr: 0.0010\n",
      "Epoch 50/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.0627\n",
      "Epoch 50: loss improved from 2.07306 to 2.06273, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 83ms/step - loss: 2.0627 - lr: 0.0010\n",
      "Epoch 51/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.0041\n",
      "Epoch 51: loss improved from 2.06273 to 2.00407, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 2.0041 - lr: 0.0010\n",
      "Epoch 52/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.9997\n",
      "Epoch 52: loss improved from 2.00407 to 1.99975, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 74ms/step - loss: 1.9997 - lr: 0.0010\n",
      "Epoch 53/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.9498\n",
      "Epoch 53: loss improved from 1.99975 to 1.94977, saving model to nextword1.h5\n",
      "61/61 [==============================] - 4s 73ms/step - loss: 1.9498 - lr: 0.0010\n",
      "Epoch 54/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.9176\n",
      "Epoch 54: loss improved from 1.94977 to 1.91765, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 77ms/step - loss: 1.9176 - lr: 0.0010\n",
      "Epoch 55/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.8814\n",
      "Epoch 55: loss improved from 1.91765 to 1.88144, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 77ms/step - loss: 1.8814 - lr: 0.0010\n",
      "Epoch 56/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.8519\n",
      "Epoch 56: loss improved from 1.88144 to 1.85191, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 74ms/step - loss: 1.8519 - lr: 0.0010\n",
      "Epoch 57/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.8248\n",
      "Epoch 57: loss improved from 1.85191 to 1.82485, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 74ms/step - loss: 1.8248 - lr: 0.0010\n",
      "Epoch 58/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.8136\n",
      "Epoch 58: loss improved from 1.82485 to 1.81362, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 77ms/step - loss: 1.8136 - lr: 0.0010\n",
      "Epoch 59/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.8288\n",
      "Epoch 59: loss did not improve from 1.81362\n",
      "61/61 [==============================] - 4s 72ms/step - loss: 1.8288 - lr: 0.0010\n",
      "Epoch 60/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.7824\n",
      "Epoch 60: loss improved from 1.81362 to 1.78240, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 74ms/step - loss: 1.7824 - lr: 0.0010\n",
      "Epoch 61/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.7657\n",
      "Epoch 61: loss improved from 1.78240 to 1.76568, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 82ms/step - loss: 1.7657 - lr: 0.0010\n",
      "Epoch 62/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.7527\n",
      "Epoch 62: loss improved from 1.76568 to 1.75266, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 1.7527 - lr: 0.0010\n",
      "Epoch 63/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.7243\n",
      "Epoch 63: loss improved from 1.75266 to 1.72432, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 1.7243 - lr: 0.0010\n",
      "Epoch 64/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.7207\n",
      "Epoch 64: loss improved from 1.72432 to 1.72072, saving model to nextword1.h5\n",
      "61/61 [==============================] - 7s 120ms/step - loss: 1.7207 - lr: 0.0010\n",
      "Epoch 65/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.7055\n",
      "Epoch 65: loss improved from 1.72072 to 1.70551, saving model to nextword1.h5\n",
      "61/61 [==============================] - 7s 110ms/step - loss: 1.7055 - lr: 0.0010\n",
      "Epoch 66/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.6553\n",
      "Epoch 66: loss improved from 1.70551 to 1.65533, saving model to nextword1.h5\n",
      "61/61 [==============================] - 8s 128ms/step - loss: 1.6553 - lr: 0.0010\n",
      "Epoch 67/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.6366\n",
      "Epoch 67: loss improved from 1.65533 to 1.63660, saving model to nextword1.h5\n",
      "61/61 [==============================] - 23s 379ms/step - loss: 1.6366 - lr: 0.0010\n",
      "Epoch 68/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.6447\n",
      "Epoch 68: loss did not improve from 1.63660\n",
      "61/61 [==============================] - 5s 75ms/step - loss: 1.6447 - lr: 0.0010\n",
      "Epoch 69/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.6401\n",
      "Epoch 69: loss did not improve from 1.63660\n",
      "61/61 [==============================] - 5s 74ms/step - loss: 1.6401 - lr: 0.0010\n",
      "Epoch 70/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.6199\n",
      "Epoch 70: loss improved from 1.63660 to 1.61990, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 1.6199 - lr: 0.0010\n",
      "Epoch 71/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.6260\n",
      "Epoch 71: loss did not improve from 1.61990\n",
      "61/61 [==============================] - 4s 69ms/step - loss: 1.6260 - lr: 0.0010\n",
      "Epoch 72/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.5933\n",
      "Epoch 72: loss improved from 1.61990 to 1.59330, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 1.5933 - lr: 0.0010\n",
      "Epoch 73/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.5601\n",
      "Epoch 73: loss improved from 1.59330 to 1.56010, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 82ms/step - loss: 1.5601 - lr: 0.0010\n",
      "Epoch 74/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.5449\n",
      "Epoch 74: loss improved from 1.56010 to 1.54492, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 1.5449 - lr: 0.0010\n",
      "Epoch 75/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.5318\n",
      "Epoch 75: loss improved from 1.54492 to 1.53177, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 82ms/step - loss: 1.5318 - lr: 0.0010\n",
      "Epoch 76/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.5293\n",
      "Epoch 76: loss improved from 1.53177 to 1.52926, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 86ms/step - loss: 1.5293 - lr: 0.0010\n",
      "Epoch 77/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.5140\n",
      "Epoch 77: loss improved from 1.52926 to 1.51397, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 84ms/step - loss: 1.5140 - lr: 0.0010\n",
      "Epoch 78/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.4955\n",
      "Epoch 78: loss improved from 1.51397 to 1.49550, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 81ms/step - loss: 1.4955 - lr: 0.0010\n",
      "Epoch 79/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.4777\n",
      "Epoch 79: loss improved from 1.49550 to 1.47770, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 84ms/step - loss: 1.4777 - lr: 0.0010\n",
      "Epoch 80/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.4429\n",
      "Epoch 80: loss improved from 1.47770 to 1.44290, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 1.4429 - lr: 0.0010\n",
      "Epoch 81/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.4414\n",
      "Epoch 81: loss improved from 1.44290 to 1.44145, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 76ms/step - loss: 1.4414 - lr: 0.0010\n",
      "Epoch 82/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.4430\n",
      "Epoch 82: loss did not improve from 1.44145\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 1.4430 - lr: 0.0010\n",
      "Epoch 83/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.4405\n",
      "Epoch 83: loss improved from 1.44145 to 1.44050, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 86ms/step - loss: 1.4405 - lr: 0.0010\n",
      "Epoch 84/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.4148\n",
      "Epoch 84: loss improved from 1.44050 to 1.41476, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 75ms/step - loss: 1.4148 - lr: 0.0010\n",
      "Epoch 85/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.4589\n",
      "Epoch 85: loss did not improve from 1.41476\n",
      "61/61 [==============================] - 4s 72ms/step - loss: 1.4589 - lr: 0.0010\n",
      "Epoch 86/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.4615\n",
      "Epoch 86: loss did not improve from 1.41476\n",
      "61/61 [==============================] - 5s 77ms/step - loss: 1.4615 - lr: 0.0010\n",
      "Epoch 87/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.4262\n",
      "Epoch 87: loss did not improve from 1.41476\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "61/61 [==============================] - 5s 74ms/step - loss: 1.4262 - lr: 0.0010\n",
      "Epoch 88/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.0690\n",
      "Epoch 88: loss improved from 1.41476 to 1.06903, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 1.0690 - lr: 2.0000e-04\n",
      "Epoch 89/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.9280\n",
      "Epoch 89: loss improved from 1.06903 to 0.92803, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 83ms/step - loss: 0.9280 - lr: 2.0000e-04\n",
      "Epoch 90/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.8789\n",
      "Epoch 90: loss improved from 0.92803 to 0.87893, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 84ms/step - loss: 0.8789 - lr: 2.0000e-04\n",
      "Epoch 91/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.8543\n",
      "Epoch 91: loss improved from 0.87893 to 0.85428, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 76ms/step - loss: 0.8543 - lr: 2.0000e-04\n",
      "Epoch 92/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.8382\n",
      "Epoch 92: loss improved from 0.85428 to 0.83818, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 83ms/step - loss: 0.8382 - lr: 2.0000e-04\n",
      "Epoch 93/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.8266\n",
      "Epoch 93: loss improved from 0.83818 to 0.82662, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.8266 - lr: 2.0000e-04\n",
      "Epoch 94/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.8195\n",
      "Epoch 94: loss improved from 0.82662 to 0.81949, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 76ms/step - loss: 0.8195 - lr: 2.0000e-04\n",
      "Epoch 95/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.8140\n",
      "Epoch 95: loss improved from 0.81949 to 0.81405, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.8140 - lr: 2.0000e-04\n",
      "Epoch 96/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.8074\n",
      "Epoch 96: loss improved from 0.81405 to 0.80736, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 81ms/step - loss: 0.8074 - lr: 2.0000e-04\n",
      "Epoch 97/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.8043\n",
      "Epoch 97: loss improved from 0.80736 to 0.80428, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.8043 - lr: 2.0000e-04\n",
      "Epoch 98/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7964\n",
      "Epoch 98: loss improved from 0.80428 to 0.79636, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 0.7964 - lr: 2.0000e-04\n",
      "Epoch 99/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7950\n",
      "Epoch 99: loss improved from 0.79636 to 0.79497, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 82ms/step - loss: 0.7950 - lr: 2.0000e-04\n",
      "Epoch 100/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7937\n",
      "Epoch 100: loss improved from 0.79497 to 0.79368, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.7937 - lr: 2.0000e-04\n",
      "Epoch 101/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7900\n",
      "Epoch 101: loss improved from 0.79368 to 0.79004, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 77ms/step - loss: 0.7900 - lr: 2.0000e-04\n",
      "Epoch 102/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7876\n",
      "Epoch 102: loss improved from 0.79004 to 0.78756, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 82ms/step - loss: 0.7876 - lr: 2.0000e-04\n",
      "Epoch 103/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7852\n",
      "Epoch 103: loss improved from 0.78756 to 0.78516, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.7852 - lr: 2.0000e-04\n",
      "Epoch 104/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7806\n",
      "Epoch 104: loss improved from 0.78516 to 0.78056, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 75ms/step - loss: 0.7806 - lr: 2.0000e-04\n",
      "Epoch 105/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7798\n",
      "Epoch 105: loss improved from 0.78056 to 0.77980, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 82ms/step - loss: 0.7798 - lr: 2.0000e-04\n",
      "Epoch 106/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7759\n",
      "Epoch 106: loss improved from 0.77980 to 0.77593, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 81ms/step - loss: 0.7759 - lr: 2.0000e-04\n",
      "Epoch 107/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7748\n",
      "Epoch 107: loss improved from 0.77593 to 0.77479, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 74ms/step - loss: 0.7748 - lr: 2.0000e-04\n",
      "Epoch 108/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7746\n",
      "Epoch 108: loss improved from 0.77479 to 0.77455, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 74ms/step - loss: 0.7746 - lr: 2.0000e-04\n",
      "Epoch 109/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7693\n",
      "Epoch 109: loss improved from 0.77455 to 0.76931, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 76ms/step - loss: 0.7693 - lr: 2.0000e-04\n",
      "Epoch 110/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7705\n",
      "Epoch 110: loss did not improve from 0.76931\n",
      "61/61 [==============================] - 4s 69ms/step - loss: 0.7705 - lr: 2.0000e-04\n",
      "Epoch 111/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7685\n",
      "Epoch 111: loss improved from 0.76931 to 0.76852, saving model to nextword1.h5\n",
      "61/61 [==============================] - 4s 72ms/step - loss: 0.7685 - lr: 2.0000e-04\n",
      "Epoch 112/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7653\n",
      "Epoch 112: loss improved from 0.76852 to 0.76529, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 76ms/step - loss: 0.7653 - lr: 2.0000e-04\n",
      "Epoch 113/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7656\n",
      "Epoch 113: loss did not improve from 0.76529\n",
      "61/61 [==============================] - 4s 73ms/step - loss: 0.7656 - lr: 2.0000e-04\n",
      "Epoch 114/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7652\n",
      "Epoch 114: loss improved from 0.76529 to 0.76518, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 76ms/step - loss: 0.7652 - lr: 2.0000e-04\n",
      "Epoch 115/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7637\n",
      "Epoch 115: loss improved from 0.76518 to 0.76372, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 75ms/step - loss: 0.7637 - lr: 2.0000e-04\n",
      "Epoch 116/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7606\n",
      "Epoch 116: loss improved from 0.76372 to 0.76065, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 0.7606 - lr: 2.0000e-04\n",
      "Epoch 117/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7580\n",
      "Epoch 117: loss improved from 0.76065 to 0.75804, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 77ms/step - loss: 0.7580 - lr: 2.0000e-04\n",
      "Epoch 118/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7579\n",
      "Epoch 118: loss improved from 0.75804 to 0.75789, saving model to nextword1.h5\n",
      "61/61 [==============================] - 4s 74ms/step - loss: 0.7579 - lr: 2.0000e-04\n",
      "Epoch 119/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7566\n",
      "Epoch 119: loss improved from 0.75789 to 0.75658, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 76ms/step - loss: 0.7566 - lr: 2.0000e-04\n",
      "Epoch 120/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7575\n",
      "Epoch 120: loss did not improve from 0.75658\n",
      "61/61 [==============================] - 4s 71ms/step - loss: 0.7575 - lr: 2.0000e-04\n",
      "Epoch 121/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7557\n",
      "Epoch 121: loss improved from 0.75658 to 0.75573, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 76ms/step - loss: 0.7557 - lr: 2.0000e-04\n",
      "Epoch 122/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7522\n",
      "Epoch 122: loss improved from 0.75573 to 0.75218, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 74ms/step - loss: 0.7522 - lr: 2.0000e-04\n",
      "Epoch 123/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7524\n",
      "Epoch 123: loss did not improve from 0.75218\n",
      "61/61 [==============================] - 4s 72ms/step - loss: 0.7524 - lr: 2.0000e-04\n",
      "Epoch 124/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7498\n",
      "Epoch 124: loss improved from 0.75218 to 0.74977, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 77ms/step - loss: 0.7498 - lr: 2.0000e-04\n",
      "Epoch 125/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7501\n",
      "Epoch 125: loss did not improve from 0.74977\n",
      "61/61 [==============================] - 4s 68ms/step - loss: 0.7501 - lr: 2.0000e-04\n",
      "Epoch 126/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7484\n",
      "Epoch 126: loss improved from 0.74977 to 0.74837, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 76ms/step - loss: 0.7484 - lr: 2.0000e-04\n",
      "Epoch 127/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7455\n",
      "Epoch 127: loss improved from 0.74837 to 0.74548, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 76ms/step - loss: 0.7455 - lr: 2.0000e-04\n",
      "Epoch 128/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7452\n",
      "Epoch 128: loss improved from 0.74548 to 0.74519, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 76ms/step - loss: 0.7452 - lr: 2.0000e-04\n",
      "Epoch 129/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7448\n",
      "Epoch 129: loss improved from 0.74519 to 0.74484, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 75ms/step - loss: 0.7448 - lr: 2.0000e-04\n",
      "Epoch 130/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7443\n",
      "Epoch 130: loss improved from 0.74484 to 0.74426, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.7443 - lr: 2.0000e-04\n",
      "Epoch 131/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7420\n",
      "Epoch 131: loss improved from 0.74426 to 0.74196, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 0.7420 - lr: 2.0000e-04\n",
      "Epoch 132/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7417\n",
      "Epoch 132: loss improved from 0.74196 to 0.74166, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 77ms/step - loss: 0.7417 - lr: 2.0000e-04\n",
      "Epoch 133/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7404\n",
      "Epoch 133: loss improved from 0.74166 to 0.74035, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 82ms/step - loss: 0.7404 - lr: 2.0000e-04\n",
      "Epoch 134/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7373\n",
      "Epoch 134: loss improved from 0.74035 to 0.73727, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 86ms/step - loss: 0.7373 - lr: 2.0000e-04\n",
      "Epoch 135/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7399\n",
      "Epoch 135: loss did not improve from 0.73727\n",
      "61/61 [==============================] - 4s 67ms/step - loss: 0.7399 - lr: 2.0000e-04\n",
      "Epoch 136/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7367\n",
      "Epoch 136: loss improved from 0.73727 to 0.73673, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 77ms/step - loss: 0.7367 - lr: 2.0000e-04\n",
      "Epoch 137/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7374\n",
      "Epoch 137: loss did not improve from 0.73673\n",
      "61/61 [==============================] - 5s 90ms/step - loss: 0.7374 - lr: 2.0000e-04\n",
      "Epoch 138/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7366\n",
      "Epoch 138: loss improved from 0.73673 to 0.73659, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 81ms/step - loss: 0.7366 - lr: 2.0000e-04\n",
      "Epoch 139/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7363\n",
      "Epoch 139: loss improved from 0.73659 to 0.73630, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 86ms/step - loss: 0.7363 - lr: 2.0000e-04\n",
      "Epoch 140/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7332\n",
      "Epoch 140: loss improved from 0.73630 to 0.73321, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 90ms/step - loss: 0.7332 - lr: 2.0000e-04\n",
      "Epoch 141/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7339\n",
      "Epoch 141: loss did not improve from 0.73321\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 0.7339 - lr: 2.0000e-04\n",
      "Epoch 142/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7346\n",
      "Epoch 142: loss did not improve from 0.73321\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.7346 - lr: 2.0000e-04\n",
      "Epoch 143/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7318\n",
      "Epoch 143: loss improved from 0.73321 to 0.73177, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 81ms/step - loss: 0.7318 - lr: 2.0000e-04\n",
      "Epoch 144/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7282\n",
      "Epoch 144: loss improved from 0.73177 to 0.72824, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 0.7282 - lr: 2.0000e-04\n",
      "Epoch 145/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7302\n",
      "Epoch 145: loss did not improve from 0.72824\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 0.7302 - lr: 2.0000e-04\n",
      "Epoch 146/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7297\n",
      "Epoch 146: loss did not improve from 0.72824\n",
      "61/61 [==============================] - 5s 90ms/step - loss: 0.7297 - lr: 2.0000e-04\n",
      "Epoch 147/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7303\n",
      "Epoch 147: loss did not improve from 0.72824\n",
      "\n",
      "Epoch 147: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "61/61 [==============================] - 5s 81ms/step - loss: 0.7303 - lr: 2.0000e-04\n",
      "Epoch 148/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.6731\n",
      "Epoch 148: loss improved from 0.72824 to 0.67314, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 0.6731 - lr: 1.0000e-04\n",
      "Epoch 149/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.6685\n",
      "Epoch 149: loss improved from 0.67314 to 0.66852, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 85ms/step - loss: 0.6685 - lr: 1.0000e-04\n",
      "Epoch 150/150\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.6665\n",
      "Epoch 150: loss improved from 0.66852 to 0.66652, saving model to nextword1.h5\n",
      "61/61 [==============================] - 5s 89ms/step - loss: 0.6665 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21ee8ad6710>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=150, batch_size=64, callbacks=[checkpoint, reduce, tensorboard_Visualization])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d0c32c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ea9993ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.10.0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b14afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cf84f56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 20216), started 1:47:27 ago. (Use '!kill 20216' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f717785a073d4292\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f717785a073d4292\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/scalars\n",
    "from IPython.display import Image \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572556d6",
   "metadata": {},
   "source": [
    "from IPython.display import Image \n",
    "pil_img = Image(filename='graph1.png')\n",
    "display(pil_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64581dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
